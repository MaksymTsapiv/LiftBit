services:
  # <<-- NGINX -->>
  nginx:
    # depends_on:
    #   - files-ms
    restart: always
    build:
      context: ./nginx
    ports:
      - ${PORT}:3000

  # <<-- MICROSERVICES -->>
  files-ms:
    build:
      context: ./files-ms
    restart: unless-stopped
    depends_on:
      - kafka-broker

  storage-ms:
    build:
      context: ./storage-ms
    env_file:
        - ./storage-ms/.env


  metadata-ms:
    build:
      context: ./metadata-ms
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      metadata-db:
        condition: service_healthy

  metadata-db:
    image: cassandra:latest
    healthcheck:
      test: ["CMD-SHELL", "[ $$(nodetool statusgossip) = running ]"]
      interval: 30s
      timeout: 10s
      retries: 5

  metadata-db-setuper:
    image: cassandra:latest
    depends_on:
      metadata-db:
        condition:
          service_healthy
    restart: "no"
    entrypoint: ["/setup_metadata_db.sh"]
    volumes:
      - ./metadata-db-setuper/cql/create_schema.cql:/create_schema.cql
      - ./metadata-db-setuper/setup_metadata_db.sh:/setup_metadata_db.sh

  # <<-- KAFKA stuff -->>
  zookeeper-server:
    image: "bitnami/zookeeper:latest"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    healthcheck:
      test: nc -z localhost 2181 || exit -1
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  kafka-broker:
    image: "bitnami/kafka:latest"
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper-server:2181
    depends_on:
      zookeeper-server:
        condition: service_healthy

  kafka-setuper:
    image: "bitnami/kafka:latest"
    depends_on:
      - kafka-broker
    restart: "no"
    entrypoint: ["/init.sh"]
    volumes:
      - ./kafka-setuper/init.sh:/init.sh

  # <<-- SPARK stuff -->>
  spark-master:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./analytics:/opt/app:rw
  spark-worker:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./analytics:/opt/app:rw
  job-submitter:
    image: docker.io/bitnami/spark:3
    user: root
    depends_on:
      - spark-master
      - spark-worker
      - kafka-broker
    volumes:
      - ./analytics:/opt/app:rw
    entrypoint: ["/opt/app/submit-job.sh"]

  sqlite3:
    image: nouchka/sqlite3:latest
    stdin_open: true
    tty: true

  login-ms:
    build:
      context: ./login-ms
      dockerfile: Dockerfile
